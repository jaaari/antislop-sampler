{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies:\n",
    "\n",
    "#!pip install transformers ipywidgets IPython\n",
    "\n",
    "# If running on Colab:\n",
    "#!git clone https://github.com/sam-paech/antislop-sampler.git\n",
    "#!mv antislop-sampler/src .\n",
    "#!mv antislop-sampler/slop_phrase_prob_adjustments.json ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    ")\n",
    "from src.antislop_generate import generate_antislop, chat_antislop\n",
    "\n",
    "# Enable efficient transfer for Hugging Face models\n",
    "os.environ['HF_HUB_ENABLE_HF_TRANSFER'] = \"1\"\n",
    "\n",
    "# Set the device to 'cuda' if available, else 'cpu'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Specify the model name (replace with your preferred model)\n",
    "model_name = \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "#model_name = \"unsloth/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, trust_remote_code=True)\n",
    "model.to(device)\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "if os.path.exists('slop_phrase_prob_adjustments.json'):\n",
    "    with open('slop_phrase_prob_adjustments.json', 'r') as f:\n",
    "        slop_phrase_prob_adjustments = dict(json.load(f)[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write a story about Elara, the weaver of tapestries in future Technopolis. In the bustling city, a group of \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of Technopolis, a city of towering skyscrapers and humming machinery, Elara's workshop stood out among the sea of identical, high-tech buildings. The sign above her door read \"Moonwhisper's Tapestry Weavers,\" and the windows were filled with a kaleidoscope of colors, as if the very fabric of the city itself was woven into the tapestries.\n",
      "\n",
      "Elara, a skilled weaver with hair as silver as the moon and eyes that shone like"
     ]
    }
   ],
   "source": [
    "# Chat generation with streaming\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "tokens = []\n",
    "text = ''\n",
    "for token in chat_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    messages=messages,\n",
    "    max_new_tokens=400,\n",
    "    # Antislop sampling may be less reliable at low temperatures.\n",
    "    #temperature=1,    \n",
    "    #min_p=0.1,\n",
    "    temperature=0.01,\n",
    "    # The adjustment_strength param scales how strongly the probability adjustments are applied.\n",
    "    # A value of 1 means the values in slop_phrase_prob_adjustments (or the defaults) are used unmodified.\n",
    "    # Reasonable values are 0 (disabled) thru 100+ (effectively banning the list).\n",
    "    adjustment_strength=100.0,\n",
    "    # Optional: Provide a list of slop phrases and probability adjustments\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    enforce_json=False,\n",
    "    antislop_enabled=False,\n",
    "    ban_slop_first_tokens=True,\n",
    "    streaming=True,\n",
    "    stream_smoothing=True, # On by default; this will smooth out the stutters from backtracking.\n",
    "):\n",
    "    tokens.append(token)\n",
    "    full_text = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "    new_text = full_text[len(text):]\n",
    "    text = full_text\n",
    "    print(new_text, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of Future City, a sprawling technological marvel, the air was alive with the hum of machinery and the chatter of pedestrians. The city's residents moved with purpose, their footsteps echoing off the sleek, silver skyscrapers that pierced the clouds. Among the throngs was a young woman named Elian, her dark hair tied back in a tight ponytail as she hurried down the main thoroughfare.\n",
      "\n",
      "Elian was a weaver, one of the city's skilled artisans who brought beauty and magic to the fabric of its inhabitants. Her workshop, a cozy room tucked away in a quiet alley, was a haven of creativity and tranquility. As she worked, her fingers moved deftly, the shuttle of her loom weaving a tale of wonder and enchantment.\n",
      "\n",
      "The weavers of Future City were renowned for their extraordinary talent, their creations imbued with the essence of the city's energy. Elian's own work was a fusion of traditional techniques and advanced machinery, allowing her to craft fabrics that shone like stars and pulsed with the heartbeat of the city.\n",
      "\n",
      "As Elian worked, a group of individuals caught her eye. There was Arin, the burly engineer who had designed the city's infrastructure; Lyra, the young hacker who had uncovered hidden patterns in the code; and Jax, the charismatic performer who had mastered the ancient art of acrobatics. Together, they formed an eclectic group known as the \"Synthetix,\" united by their passion for innovation and their love of storytelling.\n",
      "\n",
      "Their latest project was a grand commission from the city's governing council, a massive mural that would adorn the main square and celebrate the city's \n"
     ]
    }
   ],
   "source": [
    "# Chat generation without streaming\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "generated_text = chat_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    messages=messages,\n",
    "    max_length=400,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    adjustment_strength=100.0,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    enforce_json=False,\n",
    "    antislop_enabled=True,\n",
    "    regex_bans=['(?i)not [^.!?]{3,60} but'], # if these regex expressions are matched, we backtrack, ban that continuation and retry\n",
    "    streaming=False\n",
    ")\n",
    "print(tokenizer.decode(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " urchins stumble upon her at the market square, and a young girl named Aria discovers her talent.\n",
      "\n",
      "---\n",
      "\n",
      "The sun beat down on the market square, casting a warm glow over the crowded stalls. Vendors hawked their wares – fresh produce, exotic spices, and handmade crafts – while the smell of roasting meats and baking bread filled the air. In the midst of it all, a lone weaver sat at her stall, her fingers moving deftly as she wove a new design onto a large piece of fabric.\n",
      "\n",
      "The weaver, a young woman with a wild tangle of curly hair and a warm smile, worked with a quiet focus. Her fingers flew across the loom, the threads shimmering and glowing as she brought her vision to life. Aria, a young girl with a mop of curly brown hair and a curious gaze, wandered through the market, her eyes scanning the stalls for scraps of fabric to use in her own projects.\n",
      "\n",
      "As she passed by the weaver's stall, Aria caught sight of the beautiful, swirling patterns that covered the fabric. She felt an instant connection to the artistry, the creativity, and the beauty that radiated from the weaver's loom. The young girl's eyes locked onto the weaver, and she felt a shiver run down her spine.\n",
      "\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "# generate without streaming\n",
    "prompt_with_template = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "generated_text = generate_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_length=300,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    adjustment_strength=100.0,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    enforce_json=False,\n",
    "    antislop_enabled=True,\n",
    "    streaming=False\n",
    ")        \n",
    "print(tokenizer.decode(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5 people gather in a hidden alleyway, each with a mysterious device in their hand. They are about to participate in a secret event, where they will compete in a tournament of wit and strategy, but as they begin, they realize that each of them has been sent by a powerful corporation to spy on each other, and a mysterious figure lurks in the shadows.\n",
      "\n",
      "The group consists of:\n",
      "\n",
      "1.  **Aurora, a skilled hacker from the cybernetic gang, \"The Codekeepers\"**\n",
      "2.  **Lysander, a master strategist from the espionage agency \"The Shadowhand\"**\n",
      "3.  **Mira, a brilliant scientist from the research facility \"The Nexus\"**\n",
      "4.  **Caspian, a charismatic con artist with ties to the underworld**\n",
      "5.  **Nova, a rebellious young artist with a hidden past**\n",
      "\n",
      "As they enter the tournament hall, they are greeted by the host, **Ryker**, a charismatic and suave corporate executive. Ryker explains the rules of the tournament, but as the competitors begin to mingle and exchange information, they start to realize that something is amiss.\n",
      "\n",
      "Each of the competitors is receiving a mysterious device from a different corporation, and they all seem to have a hidden agenda. The device is a small, sleek box with a glowing screen"
     ]
    }
   ],
   "source": [
    "# generate with streaming\n",
    "prompt_with_template = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "tokens = []\n",
    "text = \"\"\n",
    "for token in generate_antislop(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    max_length=300,\n",
    "    temperature=1,\n",
    "    min_p=0.1,\n",
    "    slop_phrase_prob_adjustments=slop_phrase_prob_adjustments,\n",
    "    adjustment_strength=100.0,\n",
    "    enforce_json=False,\n",
    "    antislop_enabled=True,\n",
    "    streaming=True\n",
    "):\n",
    "    tokens.append(token)\n",
    "    full_text = tokenizer.decode(tokens, skip_special_tokens=True)\n",
    "    new_text = full_text[len(text):]\n",
    "    text = full_text\n",
    "    print(new_text, end='', flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
